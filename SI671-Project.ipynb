{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "<string>:2: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "<string>:2: DtypeWarning: Columns (29,34,35,37) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "location_data=DataFrame()\n",
    "loaded_files = []\n",
    "for filename in os.listdir(\"data/locations\"):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        loaded_files.append(pd.read_csv(\"data/locations/\"+filename))\n",
    "location_data = pd.concat(loaded_files)\n",
    "\n",
    "detail_data=DataFrame()\n",
    "loaded_files = []\n",
    "for filename in os.listdir(\"data/details\"):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        loaded_files.append(pd.read_csv(\"data/details/\"+filename))\n",
    "detail_data = pd.concat(loaded_files)\n",
    "detail_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_data['YEAR'] = (location_data.YEARMONTH-location_data.YEARMONTH%100)//100\n",
    "location_data['MONTH'] = location_data.YEARMONTH%100\n",
    "location_data = location_data.drop(['YEARMONTH', \"LAT2\", \"LON2\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>LOCATION_INDEX</th>\n",
       "      <th>RANGE</th>\n",
       "      <th>AZIMUTH</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2030059</td>\n",
       "      <td>5548852</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LANGLEY</td>\n",
       "      <td>34.32</td>\n",
       "      <td>-93.83</td>\n",
       "      <td>1996</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2030060</td>\n",
       "      <td>5548853</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>S</td>\n",
       "      <td>YELLVILLE</td>\n",
       "      <td>36.20</td>\n",
       "      <td>-92.68</td>\n",
       "      <td>1996</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002564</td>\n",
       "      <td>5548854</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COTTER</td>\n",
       "      <td>36.27</td>\n",
       "      <td>-92.53</td>\n",
       "      <td>1996</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2030061</td>\n",
       "      <td>5548855</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COTTER</td>\n",
       "      <td>36.27</td>\n",
       "      <td>-92.53</td>\n",
       "      <td>1996</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030062</td>\n",
       "      <td>5548856</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>WSW</td>\n",
       "      <td>MOUNTAIN HOME</td>\n",
       "      <td>36.30</td>\n",
       "      <td>-92.47</td>\n",
       "      <td>1996</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EPISODE_ID  EVENT_ID  LOCATION_INDEX  RANGE AZIMUTH       LOCATION  \\\n",
       "0     2030059   5548852               1    NaN     NaN        LANGLEY   \n",
       "1     2030060   5548853               1    2.0       S      YELLVILLE   \n",
       "2     1002564   5548854               1    NaN     NaN         COTTER   \n",
       "3     2030061   5548855               1    NaN     NaN         COTTER   \n",
       "4     2030062   5548856               1    5.0     WSW  MOUNTAIN HOME   \n",
       "\n",
       "   LATITUDE  LONGITUDE  YEAR  MONTH  \n",
       "0     34.32     -93.83  1996      3  \n",
       "1     36.20     -92.68  1996      3  \n",
       "2     36.27     -92.53  1996      3  \n",
       "3     36.27     -92.53  1996      3  \n",
       "4     36.30     -92.47  1996      3  "
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10096222</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.12</td>\n",
       "      <td>-99.20</td>\n",
       "      <td>35.17</td>\n",
       "      <td>-99.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10120412</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.90</td>\n",
       "      <td>-98.60</td>\n",
       "      <td>31.73</td>\n",
       "      <td>-98.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104927</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.58</td>\n",
       "      <td>-75.70</td>\n",
       "      <td>40.65</td>\n",
       "      <td>-75.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1830</td>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104928</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.60</td>\n",
       "      <td>-76.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195007</td>\n",
       "      <td>24</td>\n",
       "      <td>1440</td>\n",
       "      <td>195007</td>\n",
       "      <td>24</td>\n",
       "      <td>1440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104929</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.63</td>\n",
       "      <td>-79.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0           195004         28        1445         195004       28      1445   \n",
       "1           195004         29        1530         195004       29      1530   \n",
       "2           195007          5        1800         195007        5      1800   \n",
       "3           195007          5        1830         195007        5      1830   \n",
       "4           195007         24        1440         195007       24      1440   \n",
       "\n",
       "   EPISODE_ID  EVENT_ID         STATE  STATE_FIPS     ...      END_RANGE  \\\n",
       "0         NaN  10096222      OKLAHOMA        40.0     ...            0.0   \n",
       "1         NaN  10120412         TEXAS        48.0     ...            0.0   \n",
       "2         NaN  10104927  PENNSYLVANIA        42.0     ...            0.0   \n",
       "3         NaN  10104928  PENNSYLVANIA        42.0     ...            0.0   \n",
       "4         NaN  10104929  PENNSYLVANIA        42.0     ...            0.0   \n",
       "\n",
       "  END_AZIMUTH END_LOCATION BEGIN_LAT  BEGIN_LON END_LAT END_LON  \\\n",
       "0         NaN          NaN     35.12     -99.20   35.17  -99.20   \n",
       "1         NaN          NaN     31.90     -98.60   31.73  -98.60   \n",
       "2         NaN          NaN     40.58     -75.70   40.65  -75.47   \n",
       "3         NaN          NaN     40.60     -76.75     NaN     NaN   \n",
       "4         NaN          NaN     41.63     -79.68     NaN     NaN   \n",
       "\n",
       "  EPISODE_NARRATIVE EVENT_NARRATIVE DATA_SOURCE  \n",
       "0               NaN             NaN         PUB  \n",
       "1               NaN             NaN         PUB  \n",
       "2               NaN             NaN         PUB  \n",
       "3               NaN             NaN         PUB  \n",
       "4               NaN             NaN         PUB  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the Time related strings to a DateTime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Pad the \"DAY\" columns to length 2 so the date parser can do it's thing\n",
    "detail_data.BEGIN_DAY = detail_data.BEGIN_DAY.map(str).str.pad(2,fillchar='0')\n",
    "detail_data.END_DAY = detail_data.END_DAY.map(str).str.pad(2,fillchar='0')\n",
    "# ditto with the Time, except we're padding to the right this time\n",
    "detail_data.BEGIN_TIME = detail_data.BEGIN_TIME.map(str).str.pad(4,side=\"right\",fillchar='0')\n",
    "detail_data.END_TIME = detail_data.END_TIME.map(str).str.pad(4,side=\"right\",fillchar='0')\n",
    "# create a new column by concating the three date/time related columns and convert the result to a datetime\n",
    "detail_data['BEGIN_DATE']=detail_data.BEGIN_YEARMONTH.map(str)+\" \"+detail_data.BEGIN_DAY.map(str)+\" \"+detail_data.BEGIN_TIME.map(str)\n",
    "detail_data.BEGIN_DATE=pd.to_datetime(detail_data.BEGIN_DATE, format='%Y%m %d %H%M', errors='coerce')\n",
    "\n",
    "detail_data['END_DATE']=detail_data.END_YEARMONTH.map(str)+\" \"+detail_data.END_DAY.map(str)+\" \"+detail_data.END_TIME.map(str)\n",
    "detail_data.END_DATE=pd.to_datetime(detail_data.END_DATE, format='%Y%m %d %H%M', errors='coerce')\n",
    "\n",
    "# drop the old columns\n",
    "detail_data = detail_data.drop(['BEGIN_YEARMONTH', \"END_YEARMONTH\",'BEGIN_DAY', \"END_DAY\", \"BEGIN_TIME\", \"END_TIME\"], axis=1)\n",
    "detail_data = detail_data.drop(['YEAR', \"MONTH_NAME\",'END_DATE_TIME', \"BEGIN_DATE_TIME\"], axis=1)\n",
    "\n",
    "# Columns I don't think I need at the momment\n",
    "detail_data = detail_data.drop(['WFO', 'SOURCE',\n",
    "       'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'TOR_F_SCALE',\n",
    "       'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE',\n",
    "       'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE',\n",
    "       'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH',\n",
    "       'END_LOCATION','EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'DATA_SOURCE'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correcting input errors\n",
    "There's some input errors with the Lat/Long coordinates - decimal place is just shifted, so dividing those by ten gives us the correct value (Affects 2080 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_data.loc[detail_data.BEGIN_LON < -180, 'BEGIN_LON']=detail_data.loc[detail_data.BEGIN_LON < -180, 'BEGIN_LON']/10\n",
    "detail_data.loc[detail_data.END_LON < -180, 'END_LON']=detail_data.loc[detail_data.END_LON < -180, 'END_LON']/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix inconsistencies in event type tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_data.loc[detail_data.EVENT_TYPE.isin(['HAIL FLOODING', 'HAIL/ICY ROADS']), 'EVENT_TYPE'] = 'Hail'\n",
    "detail_data.loc[detail_data.EVENT_TYPE.isin(['Heavy Wind']), 'EVENT_TYPE'] = 'High Wind'\n",
    "detail_data.loc[detail_data.EVENT_TYPE.isin(['High Snow']), 'EVENT_TYPE'] = 'Heavy Snow'\n",
    "detail_data.loc[detail_data.EVENT_TYPE.isin(['High Snow']), 'EVENT_TYPE'] = 'Heavy Snow'\n",
    "detail_data.loc[detail_data.EVENT_TYPE.isin(\n",
    "    [\n",
    "        'TORNADOES, TSTM WIND, HAIL',\n",
    "        'THUNDERSTORM WINDS/FLOODING',\n",
    "        'THUNDERSTORM WINDS/FLASH FLOOD',\n",
    "        'THUNDERSTORM WINDS LIGHTNING',\n",
    "        'THUNDERSTORM WIND/ TREES',\n",
    "        'THUNDERSTORM WIND/ TREE',\n",
    "        'THUNDERSTORM WINDS FUNNEL CLOU',\n",
    "        'THUNDERSTORM WINDS/HEAVY RAIN',\n",
    "        'THUNDERSTORM WINDS HEAVY RAIN',\n",
    "        'THUNDERSTORM WINDS/ FLOOD'\n",
    "    ]\n",
    "), 'EVENT_TYPE'] = 'Thunderstorm Wind'\n",
    "detail_data.loc[detail_data.EVENT_TYPE.isin(['TORNADO/WATERSPOUT']), 'EVENT_TYPE'] = 'Tornado'\n",
    "detail_data.loc[detail_data.EVENT_TYPE.isin(['Landslide']), 'EVENT_TYPE'] = 'Debris Flow'\n",
    "detail_data.loc[detail_data.EVENT_TYPE.isin(['Volcanic Ashfall']), 'EVENT_TYPE'] = 'Volcanic Ash'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop 14 rows tagged \"Northern Lights\" and a single row tagged 'OTHER'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_data.drop(detail_data[detail_data.EVENT_TYPE.isin(['Northern Lights', 'OTHER'])].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Categorical Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two categories - one based off of the event type and another based on my not very scientific classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_data.EVENT_TYPE = detail_data.EVENT_TYPE.astype(\"category\")\n",
    "detail_data['EVENT_CODE'] = detail_data.EVENT_TYPE.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_data['META_TYPE'] = None\n",
    "detail_data.loc[detail_data.EVENT_TYPE.isin(\n",
    "    [\n",
    "        'Avalanche',\n",
    "        'Blizzard',\n",
    "        'Cold/Wind Chill',\n",
    "        'Extreme Cold/Wind Chill',\n",
    "        'Freezing Fog',\n",
    "        'Frost/Freeze',\n",
    "        'Hail',\n",
    "        'Heavy Snow',\n",
    "        'Ice Storm',\n",
    "        'Lake-Effect Snow',\n",
    "        'Marine Hail',\n",
    "        'Sleet',\n",
    "        'Winter Storm',\n",
    "        'Winter Weather'\n",
    "    ]\n",
    "), 'META_TYPE'] = 'Cold'\n",
    "\n",
    "detail_data.loc[detail_data.EVENT_TYPE.isin(\n",
    "    [\n",
    "        'Dense Smoke',\n",
    "        'Drought',\n",
    "        'Excessive Heat',\n",
    "        'Heat',\n",
    "        'Volcanic Ash',\n",
    "        'Wildfire'\n",
    "    ]\n",
    "), 'META_TYPE'] = 'Heat'\n",
    "\n",
    "detail_data.loc[detail_data.EVENT_TYPE.isin(\n",
    "    [\n",
    "        'Debris Flow',\n",
    "        'Dense Fog',\n",
    "        'Lightning',\n",
    "        'Marine Dense Fog',\n",
    "        'Marine Lightning'\n",
    "    ]\n",
    "), 'META_TYPE'] = 'Other'\n",
    "\n",
    "detail_data.loc[detail_data.EVENT_TYPE.isin(\n",
    "    [\n",
    "        'Astronomical Low Tide',\n",
    "        'Coastal Flood',\n",
    "        'Flash Flood',\n",
    "        'Flood',\n",
    "        'Heavy Rain',\n",
    "        'High Surf',\n",
    "        'Lakeshore Flood',\n",
    "        'Rip Current',\n",
    "        'Seiche',\n",
    "        'Sneakerwave',\n",
    "        'Storm Surge/Tide',\n",
    "        'Tsunami',\n",
    "        'Waterspout'\n",
    "    ]\n",
    "), 'META_TYPE'] = 'Water'\n",
    "\n",
    "detail_data.loc[detail_data.EVENT_TYPE.isin(\n",
    "    [\n",
    "        'Dust Devil',\n",
    "        'Dust Storm',\n",
    "        'Funnel Cloud',\n",
    "        'High Wind',\n",
    "        'Hurricane',\n",
    "        'Hurricane (Typhoon)',\n",
    "        'Marine High Wind',\n",
    "        'Marine Hurricane/Typhoon',\n",
    "        'Marine Strong Wind',\n",
    "        'Marine Thunderstorm Wind',\n",
    "        'Marine Tropical Depression',\n",
    "        'Marine Tropical Storm',\n",
    "        'Strong Wind',\n",
    "        'Thunderstorm Wind',\n",
    "        'Tornado',\n",
    "        'Tropical Depression',\n",
    "        'Tropical Storm'\n",
    "    ]\n",
    "), 'META_TYPE'] = 'Wind'\n",
    "detail_data.META_TYPE = detail_data.META_TYPE.astype(\"category\")\n",
    "detail_data['META_CODE'] = detail_data.META_TYPE.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>CZ_TYPE</th>\n",
       "      <th>CZ_FIPS</th>\n",
       "      <th>CZ_NAME</th>\n",
       "      <th>CZ_TIMEZONE</th>\n",
       "      <th>INJURIES_DIRECT</th>\n",
       "      <th>...</th>\n",
       "      <th>DAMAGE_CROPS</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>BEGIN_DATE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>EVENT_CODE</th>\n",
       "      <th>META_TYPE</th>\n",
       "      <th>META_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>90722.0</td>\n",
       "      <td>544254</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Z</td>\n",
       "      <td>52</td>\n",
       "      <td>BRYAN</td>\n",
       "      <td>CST-6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>2014-09-30 23:59:00</td>\n",
       "      <td>8</td>\n",
       "      <td>Heat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EPISODE_ID  EVENT_ID     STATE  STATE_FIPS EVENT_TYPE CZ_TYPE  CZ_FIPS  \\\n",
       "1863     90722.0    544254  OKLAHOMA        40.0    Drought       Z       52   \n",
       "\n",
       "     CZ_NAME CZ_TIMEZONE  INJURIES_DIRECT    ...     DAMAGE_CROPS  BEGIN_LAT  \\\n",
       "1863   BRYAN       CST-6                0    ...              NaN        NaN   \n",
       "\n",
       "      BEGIN_LON END_LAT END_LON  BEGIN_DATE            END_DATE  EVENT_CODE  \\\n",
       "1863        NaN     NaN     NaN  2014-09-01 2014-09-30 23:59:00           8   \n",
       "\n",
       "      META_TYPE META_CODE  \n",
       "1863       Heat         1  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail_data[detail_data.META_TYPE=='Heat'].sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill in missing geographic data\n",
    "The US Census Gazetteer contains a file which provides Lat/Long for every county in the US. Combined with the FIPs codes, we can give estimated locations for events with no clear starting point (about 1/3 of the dataset - things like \"drought\" or \"Strong Wind\" that don't have a clearly defined geographic location).\n",
    "Dataset from https://www.census.gov/geo/maps-data/data/gazetteer2017.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_df = pd.read_csv('data/2017_Gaz_counties_national.txt', sep='\\t', engine='python')\n",
    "county_df['GEOID'] = county_df['GEOID'].apply(lambda x: '{0:0>5}'.format(x))\n",
    "county_df.set_index(\"GEOID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USPS</th>\n",
       "      <th>ANSICODE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ALAND</th>\n",
       "      <th>AWATER</th>\n",
       "      <th>ALAND_SQMI</th>\n",
       "      <th>AWATER_SQMI</th>\n",
       "      <th>INTPTLAT</th>\n",
       "      <th>INTPTLONG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01001</th>\n",
       "      <td>AL</td>\n",
       "      <td>161526</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>1539614693</td>\n",
       "      <td>25744269</td>\n",
       "      <td>594.449</td>\n",
       "      <td>9.940</td>\n",
       "      <td>32.532237</td>\n",
       "      <td>-86.646440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01003</th>\n",
       "      <td>AL</td>\n",
       "      <td>161527</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>4117605847</td>\n",
       "      <td>1133109409</td>\n",
       "      <td>1589.817</td>\n",
       "      <td>437.496</td>\n",
       "      <td>30.659218</td>\n",
       "      <td>-87.746067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01005</th>\n",
       "      <td>AL</td>\n",
       "      <td>161528</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>2292144656</td>\n",
       "      <td>50538698</td>\n",
       "      <td>885.002</td>\n",
       "      <td>19.513</td>\n",
       "      <td>31.870253</td>\n",
       "      <td>-85.405104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01007</th>\n",
       "      <td>AL</td>\n",
       "      <td>161529</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>1612165763</td>\n",
       "      <td>9603798</td>\n",
       "      <td>622.461</td>\n",
       "      <td>3.708</td>\n",
       "      <td>33.015893</td>\n",
       "      <td>-87.127148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01009</th>\n",
       "      <td>AL</td>\n",
       "      <td>161530</td>\n",
       "      <td>Blount County</td>\n",
       "      <td>1670079465</td>\n",
       "      <td>15039864</td>\n",
       "      <td>644.821</td>\n",
       "      <td>5.807</td>\n",
       "      <td>33.977358</td>\n",
       "      <td>-86.566440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      USPS  ANSICODE            NAME       ALAND      AWATER  ALAND_SQMI  \\\n",
       "GEOID                                                                      \n",
       "01001   AL    161526  Autauga County  1539614693    25744269     594.449   \n",
       "01003   AL    161527  Baldwin County  4117605847  1133109409    1589.817   \n",
       "01005   AL    161528  Barbour County  2292144656    50538698     885.002   \n",
       "01007   AL    161529     Bibb County  1612165763     9603798     622.461   \n",
       "01009   AL    161530   Blount County  1670079465    15039864     644.821   \n",
       "\n",
       "       AWATER_SQMI   INTPTLAT  INTPTLONG  \n",
       "GEOID                                     \n",
       "01001        9.940  32.532237 -86.646440  \n",
       "01003      437.496  30.659218 -87.746067  \n",
       "01005       19.513  31.870253 -85.405104  \n",
       "01007        3.708  33.015893 -87.127148  \n",
       "01009        5.807  33.977358 -86.566440  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in Lat/Lon for events based on county centroid\n",
    "Create a new column that combines the State and County FIPS so we can look them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_data['FIPS'] = detail_data['STATE_FIPS']*1000+detail_data['CZ_FIPS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to match up FIPS ids for events with no location info, and fill in the begin lat/lon with that counties centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the rows that are currently missing data and try to \n",
    "for i, row in detail_data[detail_data.BEGIN_LAT.isnull()].iterrows():\n",
    "    try:\n",
    "        location = county_df.loc['{0:0>5}'.format(int(row.FIPS))]\n",
    "        detail_data.loc[i,'BEGIN_LAT'] = location['INTPTLAT']\n",
    "        detail_data.loc[i,'BEGIN_LON'] = location['INTPTLONG']\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: look at filling in the remaining missing points with bp02oc18.dbx from https://www.weather.gov/gis/ZoneCounty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the matricies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = detail_data[\n",
    "    ~detail_data.BEGIN_LAT.isnull() &\n",
    "    ~detail_data.BEGIN_LON.isnull() &\n",
    "    ~detail_data.END_LAT.isnull() &\n",
    "    ~detail_data.END_LON.isnull() &\n",
    "    (detail_data.BEGIN_LAT != detail_data.END_LAT) &\n",
    "    (detail_data.BEGIN_LON != detail_data.END_LON)\n",
    "].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = lil_matrix((5783,2460), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(935, 2089) (921, 2091)\n"
     ]
    }
   ],
   "source": [
    "for id, row in test_set.iterrows():\n",
    "    start = (lat_to_index(row.BEGIN_LAT),lon_to_index(row.BEGIN_LON))\n",
    "    end = (lat_to_index(row.END_LAT),lon_to_index(row.END_LON))\n",
    "    print(start,end)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_matrix(year):\n",
    "    start = str(year)+'-01-01'\n",
    "    end = str(year+1)+'-01-01'\n",
    "    year_data = detail_data[(detail_data.BEGIN_DATE>start) & (detail_data.BEGIN_DATE<end)].dropna()\n",
    "    # trim it to just the continental US\n",
    "    year_data = year_data[\n",
    "        (year_data.BEGIN_LON > -124.7844079) &\n",
    "        (year_data.BEGIN_LON < -66.9513812) &\n",
    "        (year_data.BEGIN_LAT > 24.7433195) &\n",
    "        (year_data.BEGIN_LAT < 49.3457868)\n",
    "    ]\n",
    "    m = lil_matrix((5783,2460), dtype=np.int8)\n",
    "    for row in year_data.iterrows():\n",
    "        row = row[1]\n",
    "        col_id = lat_to_index(row.BEGIN_LAT)\n",
    "        row_id = lon_to_index(row.BEGIN_LON)\n",
    "        \n",
    "        try:\n",
    "            m[row_id,col_id] = 1\n",
    "        except:\n",
    "            print(\"bad row:\",row)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_month_matrix(year, month):\n",
    "    start = \"{:0d}-{:02d}-01\".format(year, month)\n",
    "    if month == 12:\n",
    "        month = 1\n",
    "        year += 1\n",
    "    else:\n",
    "        month+=1\n",
    "    end = \"{:0d}-{:02d}-01\".format(year, month)\n",
    "    year_data = detail_data[(detail_data.BEGIN_DATE>start) & (detail_data.BEGIN_DATE<end)].dropna()\n",
    "    # trim it to just the continental US\n",
    "    year_data = year_data[\n",
    "        (year_data.BEGIN_LON > -124.7844079) &\n",
    "        (year_data.BEGIN_LON < -66.9513812) &\n",
    "        (year_data.BEGIN_LAT > 24.7433195) &\n",
    "        (year_data.BEGIN_LAT < 49.3457868)\n",
    "    ]\n",
    "    m = lil_matrix((5783,2460), dtype=np.int16)\n",
    "    for row in year_data.iterrows():\n",
    "        row = row[1]\n",
    "        col_id = lat_to_index(row.BEGIN_LAT)\n",
    "        row_id = lon_to_index(row.BEGIN_LON)\n",
    "        for r in range(row_id-2, row_id+3):\n",
    "            for c in range(col_id-2, col_id+3):\n",
    "                try:\n",
    "                    m[r,c] = 1\n",
    "                except:\n",
    "                    print(\"bad row:\",row)\n",
    "    return m\n",
    "\n",
    "get_year_month_matrix(2000,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_to_index(x):\n",
    "    return int(x*100-2774)\n",
    "\n",
    "def lon_to_index(x):\n",
    "    return int(abs(x)*100-6695)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mats = {}\n",
    "for year in range(1996, 2017):\n",
    "    mats[str(year)] = {}\n",
    "    for month in range(1, 13):\n",
    "#         print(year, month)\n",
    "        mats[str(year)][\"{:02d}\".format(month)] = get_year_month_matrix(year, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, long = 42.28,-83.74\n",
    "lat, long = 32.45,-89.65\n",
    "\n",
    "detail_data[\n",
    "    (detail_data.BEGIN_LON > long-1) &\n",
    "    (detail_data.BEGIN_LON < long+1) &\n",
    "    (detail_data.BEGIN_LAT > lat-1) &\n",
    "    (detail_data.BEGIN_LAT < lat+1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mats['1996']['11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual(lat, lon, month, search_range=.25):\n",
    "    year = 2016\n",
    "    start = \"{:0d}-{:02d}-01\".format(year, month)\n",
    "    if month == 12:\n",
    "        month = 1\n",
    "        year += 1\n",
    "    else:\n",
    "        month+=1\n",
    "    end = \"{:0d}-{:02d}-01\".format(year, month)\n",
    "    threshold = 1/(search_range*search_range*100*100)/12\n",
    "    event_count = len(detail_data[\n",
    "        (detail_data.BEGIN_DATE>start) & \n",
    "        (detail_data.BEGIN_DATE<end) &\n",
    "        (detail_data.BEGIN_LON > lon-search_range) &\n",
    "        (detail_data.BEGIN_LON < lon+search_range) &\n",
    "        (detail_data.BEGIN_LAT > lat-search_range) &\n",
    "        (detail_data.BEGIN_LAT < lat+search_range)\n",
    "    ])\n",
    "    seen_per = event_count/(search_range*search_range*3*100*100)\n",
    "    \n",
    "    return seen_per>threshold, seen_per/threshold, seen_per\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(lat,long,month,search_range=25):\n",
    "    col_center = lat_to_index(lat)\n",
    "    row_center = lon_to_index(long)\n",
    "\n",
    "    event_count = 0\n",
    "    total_count = 0\n",
    "    y = {}\n",
    "    for year in range(1996,2015):\n",
    "        m = mats[str(year)][\"{:02d}\".format(month)]\n",
    "        y[year] = 0\n",
    "\n",
    "        for col in range(col_center-search_range, col_center+search_range+1):\n",
    "            for row in range(row_center-search_range, row_center+search_range+1):\n",
    "                if row >= 0 and row <= 5782 and col >= 0 and col <= 2459:\n",
    "                    total_count += 1\n",
    "                    val = m[row,col]\n",
    "                    if val > 0:\n",
    "                        event_count += val\n",
    "                        y[year] += val\n",
    "                    \n",
    "    count = 0\n",
    "    for e in y.values():\n",
    "        if e > 30:\n",
    "            count += 1\n",
    "    prob = min(count/len(d)*4,.99)\n",
    "    \n",
    "    return prob > 0.6, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat,long,month = 42.16,-83.44,7\n",
    "print(\"Ann Arbor\", search(lat,long,month), get_actual(lat,long,month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {1996: 0, 1997: 0, 1998: 0, 1999: 0, 2000: 0, 2001: 0, 2002: 0, 2003: 0, 2004: 0, 2005: 0, 2006: 0, 2007: 219, 2008: 49, 2009: 0, 2010: 285, 2011: 756, 2012: 253, 2013: 139, 2014: 131}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for e in d.values():\n",
    "    if e > 30:\n",
    "        count += 1\n",
    "count/len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "correct = 0\n",
    "total = 0\n",
    "pos = 0\n",
    "for random_sample_row in detail_data[(detail_data.BEGIN_DATE>'2015-01-01') & (detail_data.BEGIN_DATE<'2016-01-01')].dropna().sample(500).iterrows():\n",
    "    random_sample_row = random_sample_row[1]\n",
    "    lat,lon = random_sample_row.BEGIN_LAT, random_sample_row.BEGIN_LON\n",
    "    event_type = random_sample_row.EVENT_TYPE\n",
    "    month = random.randint(1,12)\n",
    "    \n",
    "    prediction = search(lat,lon,month)\n",
    "    actual = get_actual(lat,lon,month)\n",
    "    \n",
    "#     print(\"({}/{}-{}) {} - Prediction: {}, Actual: {}\".format(lat,lon,month,event_type,prediction,actual))\n",
    "    \n",
    "    total += 1\n",
    "    if prediction[0] == actual[0]:\n",
    "        correct += 1\n",
    "    if prediction[0]:\n",
    "        pos += 1\n",
    "\n",
    "print(\"total: {:2f}\".format(correct/total*100))\n",
    "print(\"positives:\",pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import random\n",
    "correct = 0\n",
    "total = 0\n",
    "results = {\"pos\":0,\"neg\":0,\"false_pos\":0,\"false_neg\":0}\n",
    "over_99 = {\"pos\":0,\"neg\":0}\n",
    "for random_sample_row in detail_data[(detail_data.BEGIN_DATE>'2015-01-01') & (detail_data.BEGIN_DATE<'2016-01-01')].dropna().sample(500).iterrows():\n",
    "    random_sample_row = random_sample_row[1]\n",
    "    lat,lon = random_sample_row.BEGIN_LAT, random_sample_row.BEGIN_LON\n",
    "    month = random.randint(1,12)\n",
    "    \n",
    "    prediction = search(lat,lon,month)\n",
    "    actual = get_actual(lat,lon,month)\n",
    "    \n",
    "    print(\"({}/{}-{}) Prediction: {}, Actual: {}\".format(lat,lon,month,prediction,actual))\n",
    "    \n",
    "    total += 1\n",
    "    if prediction[0] == actual[0]:\n",
    "        correct += 1\n",
    "    \n",
    "    if prediction[0] == True and actual[0] == True:\n",
    "        results[\"pos\"] += 1\n",
    "    elif prediction[0] == False and actual[0] == False:\n",
    "        results[\"neg\"] += 1\n",
    "    elif prediction[0] == True and actual[0] == False:\n",
    "        results[\"false_pos\"] += 1\n",
    "    elif prediction[0] == False and actual[0] == True:\n",
    "        results[\"false_neg\"] += 1\n",
    "        \n",
    "    if prediction[1] == 0.99:\n",
    "        if actual[0] == True:\n",
    "            over_99['pos'] += 1\n",
    "        else:\n",
    "            over_99['neg'] += 1\n",
    "        \n",
    "\n",
    "print(\"total: {:2f}\".format(correct/total*100))\n",
    "print(results)\n",
    "print(over_99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(122+244)/500\n",
    "67/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat,long,month = 40.71,-74.00,1\n",
    "print(\"Chicago\", search(lat,long,month), get_actual(lat,long,month))\n",
    "\n",
    "lat,long,month = 42.21,71.03,3\n",
    "print(\"Boston\", search(lat,long,month), get_actual(lat,long,month))\n",
    "\n",
    "lat,long,month = 42.16,-83.44,7\n",
    "print(\"Ann Arbor\", search(lat,long,month), get_actual(lat,long,month))\n",
    "\n",
    "\n",
    "lat,long,month = 29.99,-91.07,2\n",
    "print(\"Assumption, LA\", search(lat,long,month), get_actual(lat,long,month))\n",
    "\n",
    "lat,long,month = 34.73,-96.15,5\n",
    "print(\"Caddo, OK\", search(lat,long,month), get_actual(lat,long,month))\n",
    "\n",
    "lat,long,month = 29.86,-95.39,5\n",
    "print(\"Harris, TX\", search(lat,long,month), get_actual(lat,long,month))\n",
    "\n",
    "\n",
    "lat,long,month = 34.05,-118.25,6\n",
    "print(\"Los Angeles\", search(lat,long,month), get_actual(lat,long,month))\n",
    "\n",
    "lat,long,month = 32.42, -117.09,7\n",
    "print(\"San Diego\", search(lat,long,month), get_actual(lat,long,month))\n",
    "\n",
    "lat,long,month = 34.16, -118.44,11\n",
    "print(\"Simi Valley\", search(lat,long,month), get_actual(lat,long,month))\n",
    "\n",
    "lat,long,month = 38.5, -104.494,7\n",
    "print(\"Colorado Springs\", search(lat,long,month), get_actual(lat,long,month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(1,13):\n",
    "    lat,long = 34.05,-118.25\n",
    "    print(\"Los Angeles\", search(lat,long,month), get_actual(lat,long,month))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from http://www.roguebasin.com/index.php?title=Bresenham%27s_Line_Algorithm\n",
    "def bresenham_line(start, end):\n",
    "    \"\"\"Bresenham's Line Algorithm\n",
    "    Produces a list of tuples from start and end\n",
    " \n",
    "    >>> points1 = get_line((0, 0), (3, 4))\n",
    "    >>> points2 = get_line((3, 4), (0, 0))\n",
    "    >>> assert(set(points1) == set(points2))\n",
    "    >>> print points1\n",
    "    [(0, 0), (1, 1), (1, 2), (2, 3), (3, 4)]\n",
    "    >>> print points2\n",
    "    [(3, 4), (2, 3), (1, 2), (1, 1), (0, 0)]\n",
    "    \"\"\"\n",
    "    # Setup initial conditions\n",
    "    x1, y1 = start\n",
    "    x2, y2 = end\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    " \n",
    "    # Determine how steep the line is\n",
    "    is_steep = abs(dy) > abs(dx)\n",
    " \n",
    "    # Rotate line\n",
    "    if is_steep:\n",
    "        x1, y1 = y1, x1\n",
    "        x2, y2 = y2, x2\n",
    " \n",
    "    # Swap start and end points if necessary and store swap state\n",
    "    swapped = False\n",
    "    if x1 > x2:\n",
    "        x1, x2 = x2, x1\n",
    "        y1, y2 = y2, y1\n",
    "        swapped = True\n",
    " \n",
    "    # Recalculate differentials\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    " \n",
    "    # Calculate error\n",
    "    error = int(dx / 2.0)\n",
    "    ystep = 1 if y1 < y2 else -1\n",
    " \n",
    "    # Iterate over bounding box generating points between start and end\n",
    "    y = y1\n",
    "    points = []\n",
    "    for x in range(x1, x2 + 1):\n",
    "        coord = (y, x) if is_steep else (x, y)\n",
    "        points.append(coord)\n",
    "        error -= abs(dy)\n",
    "        if error < 0:\n",
    "            y += ystep\n",
    "            error += dx\n",
    " \n",
    "    # Reverse the list if the coordinates were swapped\n",
    "    if swapped:\n",
    "        points.reverse()\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
